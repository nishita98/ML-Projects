{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c04963f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566048e6",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbd6d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "nltk.download('punkt')\n",
    "import pickle\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import layers\n",
    "from keras.optimizers import SGD\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b68abc",
   "metadata": {},
   "source": [
    "# Understanding and exploring data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0b80f5",
   "metadata": {},
   "source": [
    "## Data understanding and cleaning\n",
    "\n",
    "<span style=\"color:red\">Step 2</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c41efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2\n",
    "\n",
    "data = pd.read_csv('21201394.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85b6a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ddfe60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I can observe the data imbalance using the value_counts func\n",
    "\n",
    "print(data['category'].value_counts())\n",
    "plt.figure(figsize=(8,5))\n",
    "ax = sns.countplot(x=\"category\", data=data)\n",
    "ax.set_xlabel(\"Category\", fontsize=12)\n",
    "ax.set_ylabel(\"Count\", fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0c8521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping un-nessary columns\n",
    "# Dropped unnamed: 0 as already index is present\n",
    "# Dropped link column as had repeated headline information with unique url id's\n",
    "\n",
    "data.drop(['Unnamed: 0', 'link'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8171aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# knowing structure of the data columns\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247d1fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# knowing columns\n",
    "\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c5d599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# knowing size of the dataset\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6872f255",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58656ab7",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">Step 3 (iii)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bc0e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3 i, ii are below.\n",
    "# There are many null records in the data and if I will drop them all then the size of the dataset would be affected badly\n",
    "# Therefore, according to my observation, I will remove null records based on the potential independent columns only i.e. \"headline\", \"short_description\" and based on dependent column i.e. \"category\"\n",
    "# dropping null records in the category, headline and short description columns \n",
    "\n",
    "data = data.dropna(subset=['category','headline','short_description'])\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5c2ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing null author names with a blank value\n",
    "\n",
    "data[\"authors\"].fillna(\"\", inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15ea0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping duplicates record\n",
    "\n",
    "data = data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb62a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding CategoryId column for Categories to get it's numerical representation for ML modelling\n",
    "# Home & Living denoted as 0\n",
    "# Wellness denoted as 1\n",
    "# Source: https://www.statology.org/pandas-factorize/\n",
    "\n",
    "data['CategoryId'] = data['category'].factorize()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be882636",
   "metadata": {},
   "outputs": [],
   "source": [
    "#knowing shape after data preparation\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455d06a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fd1094",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdaae3dc",
   "metadata": {},
   "source": [
    "### Create and Fit Bag of Words Model to find most common words\n",
    "\n",
    "<span style=\"color:red\">Step 3 (i)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e146fa9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Finding words more common for each category using countvectorizer\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "# Week D10W1 (combination of all steps in a function)\n",
    "def countVectorize(desc):\n",
    "    description = vectorizer.fit_transform(desc)\n",
    "    tokens_and_counts = zip(vectorizer.get_feature_names_out(), np.asarray(description.sum(axis=0)).ravel())\n",
    "    df_tokens = pd.DataFrame(tokens_and_counts, columns=['Token', 'Count'])\n",
    "    df_tokens.sort_values(\"Count\", ascending=False, inplace=True)\n",
    "    df_tokens.reset_index(inplace=True, drop=True)\n",
    "    #Most Popular Tokens\n",
    "    most_popular_tokens = df_tokens.nlargest(columns=\"Count\", n=20)\n",
    "    return most_popular_tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae666065",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">Step3 (ii) Column Selection</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd53310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reason:\n",
    "# I think both the \"headline\" and \"short description\" columns contain important information to predict the correct topical category of the text.\n",
    "# Therefore, combining them and storing them as a new column \"description\" to perform necessary NLP pre-processing on one column only.\n",
    "# Also,\n",
    "# I didn't include \"authors\" column as the same author can publish articles for both the categories and if I will perform tokenization on author name then many authors have same first names which will lead to incorrect analysis of categories.\n",
    "# And didn't include \"date\" column as I cannot see a useful pattern in dates of publishing.\n",
    "\n",
    "data[\"description\"]=data[\"headline\"]+\" \"+data[\"short_description\"]\n",
    "wellness=data[data[\"category\"]==\"WELLNESS\"][\"description\"]\n",
    "living=data[data[\"category\"]==\"HOME & LIVING\"][\"description\"]\n",
    "\n",
    "#Mean sentence length for both the categories\n",
    "mean_len_wellness = wellness.str.len().mean()\n",
    "mean_len_living = living.str.len().mean()\n",
    "\n",
    "print(\"Mean sentence length: Wellness -> \",mean_len_wellness)\n",
    "print(\"Mean sentence length: Home & Living -> \", mean_len_living)\n",
    "print(\"WELLNESS > HOME & LIVING\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4f1974",
   "metadata": {},
   "source": [
    "### Creating wordcloud representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa257ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://re-thought.com/creating-wordclouds-in-python/\n",
    "\n",
    "def make_wordcloud(text):\n",
    "    wordcloud = WordCloud(width=600, height=600).generate(text)\n",
    "    plt.figure(figsize = (10,10))\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114e7012",
   "metadata": {},
   "source": [
    "###  Most popular keywords in wellness category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45391904",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Most popular keywords in wellness category:\\n\",countVectorize(wellness))\n",
    "df_new=countVectorize(wellness).to_csv('wellness_df',header=None)\n",
    "df_wellness=pd.read_csv('wellness_df')\n",
    "print(\"---------------------------------------------\\nWellness Top Wordcloud:\")\n",
    "make_wordcloud(str(df_wellness))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5642be30",
   "metadata": {},
   "source": [
    "###  Most popular keywords in home and living category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96a9605",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Most popular keywords in home and living category:\\n\",countVectorize(living))\n",
    "hliving_top_words=countVectorize(living).to_csv('df_hliving',header=None)\n",
    "df_hliving=pd.read_csv('df_hliving')\n",
    "print(\"------------------------------------------------\\nHome & Living Top Wordcloud:\")\n",
    "make_wordcloud(str(df_hliving))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26da7367",
   "metadata": {},
   "source": [
    "# Data Preparation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938ae5fd",
   "metadata": {},
   "source": [
    "### Declared Dependent and Independent Value\n",
    "\n",
    "<span style=\"color:red\">Step 4</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf19ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# X is the independent variable\n",
    "# y is the dependent variable\n",
    "X = data.loc[:,\"description\"]\n",
    "y = data.loc[:,\"CategoryId\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b89b6c1",
   "metadata": {},
   "source": [
    "### Split the dataset into train, valid, test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce483a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am dividing the dataset on the best approach suggested generally i.e. training = 70%, vaild = 15%, test = 15% of dataset as it's not a very large dataset.\n",
    "# Source: https://www.v7labs.com/blog/train-validation-test-set\n",
    "# In this step, I will first split the dataset into train_plus_valid and test dataset.\n",
    "# Then split train_plus_valid into train dataset and valid dataset.\n",
    "\n",
    "X_train_plus_valid, X_test, y_train_plus_valid, y_test = train_test_split(X, y, random_state=0, test_size = 0.15, train_size = 0.85)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_plus_valid, y_train_plus_valid, random_state=0, test_size = 0.15/0.85, train_size = 0.7/0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3a5144",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11e96a3",
   "metadata": {},
   "source": [
    "### Concatenating and saving csv files for train, validation, test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ee31bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.concat([X_train,y_train], axis=1)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9f461e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=train_data.to_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0922cc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data = pd.concat([X_valid,y_valid], axis=1)\n",
    "valid_data=valid_data.to_csv('valid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b844b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=pd.concat([X_test,y_test], axis=1)\n",
    "test_data=test_data.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089fdaa7",
   "metadata": {},
   "source": [
    "### Pre-processing steps\n",
    "Our data is text input so to extract meaningful results we need to perform some necessary pre-processing. As better quality of data will generate better results from models. \n",
    " - Removing digits: When I searched the top words in each category, I found some numbers in it which is not                meaningful in predicting or differentiating the categories.\n",
    " - Removing tags: not useful\n",
    " - Removing special characters: not useful\n",
    " - Lowercasing text: helps with the consistency of expected output\n",
    " - Removing stopwords: do not provide meaningful information\n",
    " - Lemmatization: helps in grouping together the different inflected forms of a word. For e.g. \"health\" and \"healthy\"          to \"health\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595795f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://www.studytonight.com/python-howtos/remove-numbers-from-string-in-python\n",
    "\n",
    "def remove_digits(text):\n",
    "    text = re.sub(r'[0-9]','',text)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adc4e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://www.analyticsvidhya.com/blog/2021/12/text-classification-of-news-articles/\n",
    "\n",
    "def remove_tags(text):    \n",
    "    remove = re.compile(r'')\n",
    "    text= re.sub(remove, '', text)\n",
    "    text = re.sub(r'[^\\w\\s]','',text)\n",
    "    return text\n",
    "\n",
    "def special_char(text):\n",
    "    reviews = ''\n",
    "    for x in text:\n",
    "        if x.isalnum():\n",
    "            reviews = reviews + x\n",
    "        else:\n",
    "            reviews = reviews + ' '\n",
    "    return reviews\n",
    "\n",
    "def convert_lower(text):\n",
    "    return text.lower()\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = word_tokenize(text)\n",
    "    return [x for x in words if x not in stop_words]\n",
    "\n",
    "def lemmatize_word(text):\n",
    "    wordnet = WordNetLemmatizer()\n",
    "    return \" \".join([wordnet.lemmatize(word) for word in text])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42eb1d46",
   "metadata": {},
   "source": [
    "### Loading train dataset to perform pre-processing steps on text \n",
    "\n",
    "<span style=\"color:red\">Step 5</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b75634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The reason and choices for performing the pre-processing on data is mentioned above.\n",
    "\n",
    "train_data=pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe08303",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2405d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop(['Unnamed: 0'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60f875a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['description'] = train_data['description'].apply(remove_digits)\n",
    "train_data['description'] = train_data['description'].apply(remove_tags)\n",
    "train_data['description'] = train_data['description'].apply(special_char)\n",
    "train_data['description'] = train_data['description'].apply(convert_lower)\n",
    "train_data['description'] = train_data['description'].apply(remove_stopwords)\n",
    "train_data['description'] = train_data['description'].apply(lemmatize_word)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9e27e7",
   "metadata": {},
   "source": [
    "### Loading evaluation dataset to perform pre-processing steps on text \n",
    "\n",
    "<span style=\"color:red\">Step 5</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589e325a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The reason and choices for performing the pre-processing on data is mentioned above.\n",
    "\n",
    "valid_data=pd.read_csv('valid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bab21aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e83adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data.drop(['Unnamed: 0'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9942d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data['description'] = valid_data['description'].apply(remove_digits)\n",
    "valid_data['description'] = valid_data['description'].apply(remove_tags)\n",
    "valid_data['description'] = valid_data['description'].apply(special_char)\n",
    "valid_data['description'] = valid_data['description'].apply(convert_lower)\n",
    "valid_data['description'] = valid_data['description'].apply(remove_stopwords)\n",
    "valid_data['description'] = valid_data['description'].apply(lemmatize_word)\n",
    "valid_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb6e304",
   "metadata": {},
   "source": [
    "### Finding more common words for each target variable in training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086efc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to take a look at most common words after pre-processing\n",
    "\n",
    "print(\"Trainset - Home & Living popular keywords:\")\n",
    "countVectorize(train_data[train_data['CategoryId']==0]['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9477cc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Trainset - Wellness popular keywords:\")\n",
    "countVectorize(train_data[train_data['CategoryId']==1]['description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13105b5e",
   "metadata": {},
   "source": [
    "### Create and Fit Bag of Words Model using Tf-idf Vectorizer\n",
    "As the machine learning models work on numerically represented data therefore we need the vectorizer.\n",
    "- I chose TF-IDF vectorizer because it not only focuses on the frequency of words present in the corpus but also provides the importance of the words. Also, this technique is good for text classification or for helping a machine read words in numbers.\n",
    "- I didn't add max_features parameter to it because if I will reduce the value of max_features, there is a high chance that the majority of words chosen will be from the majority class (Wellness). This makes sense since TF-IDF is selecting features based on term frequency alone and (Wellness) records are in majority.  \n",
    "    \n",
    "    Source: https://www.analyticsvidhya.com/blog/2021/09/creating-a-movie-reviews-classifier-using-tf-idf-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e3d72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Vectorizing training and validation dataset\n",
    "# Fit the vectorizer on training dataset\n",
    "vectorizer.fit(train_data['description'])\n",
    "\n",
    "# Transforming training and validation dataset\n",
    "X_train_matrix = vectorizer.transform(train_data['description'])\n",
    "X_valid_matrix = vectorizer.transform(valid_data['description'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d4bfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking size of train data matrix generated\n",
    "\n",
    "X_train_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28747aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking size of valid data matrix generated\n",
    "\n",
    "X_valid_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9062f4c5",
   "metadata": {},
   "source": [
    "# Data Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4aa5e2d",
   "metadata": {},
   "source": [
    "## Here are my chosen binary classifiers:\n",
    "1. Support Vector Classifier (SVC): As regarded as one of the best text classification algorithm according to the below sources and is best when the number of features are high as compared to a number of data points in the dataset. Also, it's faster, takes less memory and works good on small datasets.\n",
    "\n",
    "\n",
    "2. Logistic Regression: Again regarded as one of the best binary classifier. In chapter 5: Logistic Regression of \"Speech and Language Processing\" by Daniel Jurafsky & James H. Martin. It is mentioned that in the NLP world, it’s generally accepted that Logistic Regression is a great starter algorithm for text related classification.\n",
    "\n",
    "Therefore, I chose to study both these classfiers on my dataset.\n",
    "\n",
    "Approach: Logistic Regression (LR) is a probabilistic classification model using the sigmoid function, whereas Support Vector Classifiers (SVC) are a more geometric approach that maximise the margins to each class. They are similar in that they both can divide the feature space with a decision boundary.\n",
    "\n",
    "Source: https://towardsdatascience.com/multi-class-text-classification-model-comparison-and-selection-5eb066197568#:~:text=Linear%20Support%20Vector%20Machine%20is,the%20best%20text%20classification%20algorithms.\n",
    "\n",
    "Source 2: https://medium.com/axum-labs/logistic-regression-vs-support-vector-machines-svm-c335610a3d16#:~:text=SVM%20tries%20to%20finds%20the,are%20near%20the%20optimal%20point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d3eadc",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">Step 6</span>\n",
    "\n",
    "## Fitting the model\n",
    "\n",
    "### SVC\n",
    "#### Parameters:\n",
    "1. **Linear** kernel is the most basic type of kernel, one dimensional in nature. It proves to be the best function when there are lots of features. The linear kernel is mostly preferred for text-classification problems as most of these kinds of classification problems can be linearly separated.\n",
    "2. Regularization parameter, **C** must be strictly positive, default = 1.0\n",
    "3. **Random_State** is set to **0** to get the reproducible results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058ac1fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "svc_model = SVC(kernel=\"linear\", C=1.0, random_state=0)\n",
    "svc_model.fit(X_train_matrix, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f223ec30",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "\n",
    "#### Parameters:\n",
    "1. I used **Liblinear** solver because it performs faster and better for data with high dimensionality. Also, it was the default historical approach to work with small datasets. Also, according to the following source, liblinear solver gave better accuracy.\n",
    "       Source: https://towardsdatascience.com/dont-sweat-the-solver-stuff-aea7cddc3451\n",
    "\n",
    "2. **Random_State** is set to **0** to get the reproducible results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4ab65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_reg = LogisticRegression(solver='liblinear', random_state=0)\n",
    "l_reg.fit(X_train_matrix,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753f2da6",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">Step 7</span>\n",
    "\n",
    "## Deep Learning model: CNN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ecea97",
   "metadata": {},
   "source": [
    "### Splitting the data into train, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95743d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The split is according to standards mentioned above: Train: 70%, Validation: 15%, Test: 15%\n",
    "\n",
    "X_train_plus_valid_1, X_test_1, y_train_plus_valid_1, y_test_1 = train_test_split(X, y, random_state=0, test_size = 0.15, train_size = 0.85)\n",
    "X_train_1, X_valid_1, y_train_1, y_valid_1 = train_test_split(X_train_plus_valid_1, y_train_plus_valid_1, random_state=0, test_size = 0.15/0.85, train_size = 0.7/0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb41849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing their shapes\n",
    "\n",
    "print(X_train_1.shape)\n",
    "print(X_valid_1.shape)\n",
    "print(X_test_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7318a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating x and y into respective datasets.\n",
    "\n",
    "train_data_1 = pd.concat([X_train_1,y_train_1], axis=1)\n",
    "valid_data_1 = pd.concat([X_valid_1,y_valid_1], axis=1)\n",
    "test_data_1 = pd.concat([X_test_1,y_test_1], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edadd611",
   "metadata": {},
   "source": [
    "### Pre-processing on X train, validation and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151c6567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing above mentioned pre-processing tasks on train data\n",
    "\n",
    "train_data_1['description'] = train_data_1['description'].apply(remove_digits)\n",
    "train_data_1['description'] = train_data_1['description'].apply(remove_tags)\n",
    "train_data_1['description'] = train_data_1['description'].apply(special_char)\n",
    "train_data_1['description'] = train_data_1['description'].apply(convert_lower)\n",
    "train_data_1['description'] = train_data_1['description'].apply(remove_stopwords)\n",
    "train_data_1['description'] = train_data_1['description'].apply(lemmatize_word)\n",
    "train_data_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a652bd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing above mentioned pre-processing tasks on validation data\n",
    "\n",
    "valid_data_1['description'] = valid_data_1['description'].apply(remove_digits)\n",
    "valid_data_1['description'] = valid_data_1['description'].apply(remove_tags)\n",
    "valid_data_1['description'] = valid_data_1['description'].apply(special_char)\n",
    "valid_data_1['description'] = valid_data_1['description'].apply(convert_lower)\n",
    "valid_data_1['description'] = valid_data_1['description'].apply(remove_stopwords)\n",
    "valid_data_1['description'] = valid_data_1['description'].apply(lemmatize_word)\n",
    "valid_data_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785fdaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing above mentioned pre-processing tasks on test data\n",
    "\n",
    "test_data_1['description'] = test_data_1['description'].apply(remove_digits)\n",
    "test_data_1['description'] = test_data_1['description'].apply(remove_tags)\n",
    "test_data_1['description'] = test_data_1['description'].apply(special_char)\n",
    "test_data_1['description'] = test_data_1['description'].apply(convert_lower)\n",
    "test_data_1['description'] = test_data_1['description'].apply(remove_stopwords)\n",
    "test_data_1['description'] = test_data_1['description'].apply(lemmatize_word)\n",
    "test_data_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253de89a",
   "metadata": {},
   "source": [
    "### Preparing word embedding for the deep learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbfc797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer allows to vectorize a text corpus, by turning each text into either a sequence of integers(like index of token in a dict.) or into a vector where the coeficient of each token could be binary, based on word count, based on tf-idf\n",
    "# Using keras tokenizer to build word embeddings and sequence preprocessing\n",
    "# I am considering top 10,000 frequent words for tokenization and discard rare words\n",
    "\n",
    "tokenizer = Tokenizer(num_words=10000)\n",
    "\n",
    "# Fitting tokenizer on X_train data\n",
    "tokenizer.fit_on_texts(X_train_1.tolist())\n",
    "\n",
    "print(str(tokenizer.texts_to_sequences([\"home is beautiful\"])))\n",
    "\n",
    "# The output depicts that most common words do not have a large index in our embedding space.\n",
    "# Those whose occurrence is moderate will be given a moderate index value. Also, 0 value is reserved and won’t be provided to any text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a4a892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting all the X, y data columns to list type for processing\n",
    "\n",
    "X_train_1=X_train_1.tolist()\n",
    "y_train_1=y_train_1.tolist()\n",
    "X_valid_1=X_valid_1.tolist()\n",
    "y_valid_1=y_valid_1.tolist()\n",
    "X_test_1=X_test_1.tolist()\n",
    "y_test_1=y_test_1.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7ea876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting words in the description to numercial sequences and storing them as arrays\n",
    "\n",
    "x_train=np.array(tokenizer.texts_to_sequences(X_train_1))\n",
    "x_valid=np.array(tokenizer.texts_to_sequences(X_valid_1))\n",
    "x_test=np.array(tokenizer.texts_to_sequences(X_test_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bf4210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One problem is that in each sequence is the different length of words, and to specify the length of word sequence,\n",
    "# we need to provide a maxlen parameter and to solve this, we need to use pad_sequence(),\n",
    "# which simply pads the sequence of words with zeros. I am using maxlen=100 as after pre-processing as meaningful length of text is not more than 100.\n",
    "\n",
    "maxlen = 100\n",
    "Xcnn_train = pad_sequences(x_train, padding='post', maxlen=maxlen)\n",
    "Xcnn_valid = pad_sequences(x_valid, padding='post', maxlen=maxlen)\n",
    "Xcnn_test = pad_sequences(x_test, padding='post',maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030d3969",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Xcnn_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb46012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treating the label columns for train, validation and test data\n",
    "# Converting then into categorical format as I am using loss metric as categorical_crossentropy later. Then storing them as arrays.\n",
    "\n",
    "train_labels=np.asarray(keras.utils.to_categorical(y_train_1))\n",
    "valid_labels=np.asarray(keras.utils.to_categorical(y_valid_1))\n",
    "test_labels=np.asarray(keras.utils.to_categorical(y_test_1))\n",
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3227dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing processed train and validation data as tensor slices so that it can be used while fitting the model. It will help in word masking when training the model.\n",
    "\n",
    "train_ds=tf.data.Dataset.from_tensor_slices((Xcnn_train,train_labels))\n",
    "valid_ds=tf.data.Dataset.from_tensor_slices((Xcnn_valid,valid_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44949233",
   "metadata": {},
   "source": [
    "## Deep learning: Building the CNN model\n",
    "\n",
    "Parameters\n",
    "- vocab_size: The vocab_size is the same as number of maximum features (10,000) I am considering. Also, the extremely uncommon words will get a higher index value which will be word count (10,000) + 1 because they hold some information.\n",
    "- embedding_dim: for each input word index present, the model will create a 64-bit embedding\n",
    "- input_length: max_length of sequence of sentence as mentioned above\n",
    "- embedding_regularizers.l2, bias_regularizers, kernel_regularizers: to reduce bias as unbalanced data\n",
    "- Conv1D layer: 128 filters, kernel size=3 (i.e. for each iteration it will look at 3 words at a time), activation function Relu chosen for hidden layers as standard as it works faster as well as output good results.\n",
    "- GlobalMaxPooling1D layer: Considers the maximum value out of all the word vectors so discards less weighted vectors.\n",
    "- Last dense layer: Output 2 values as binary classification and to match the labels format, activation function Sigmoid used for binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f006726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source Code: https://github.com/rsreetech/TextClassificationTensorFlowCNN/blob/master/TensorFlowTweetTextClassificationV1.ipynb\n",
    "\n",
    "\n",
    "vocab_size=10000  \n",
    "embedding_dim = 64\n",
    "\n",
    "# I am using the Sequential model A Sequential model is appropriate for a plain stack of layers where each layer has exactly one input tensor and one output tensor. Source :https://www.tensorflow.org/guide/keras/sequential_model\n",
    "textcnnmodel = Sequential()\n",
    "textcnnmodel.add(layers.Embedding(vocab_size+1, embedding_dim, input_length=maxlen, embeddings_regularizer=regularizers.l2(0.0005)))\n",
    "textcnnmodel.add(layers.Conv1D(128, 3, activation='relu',kernel_regularizer=regularizers.l2(0.0005),bias_regularizer=regularizers.l2(0.0005)))\n",
    "\n",
    "# This is followed by a pooling layer that reduces the output of the convolutional layer by half.\n",
    "textcnnmodel.add(layers.GlobalMaxPooling1D())\n",
    "textcnnmodel.add(layers.Dense(10, activation='relu'))\n",
    "\n",
    "# Dropout layers are important in training CNNs because they prevent overfitting on the training data.\n",
    "textcnnmodel.add(layers.Dropout(0.5))\n",
    "\n",
    "# The output layer uses a sigmoid activation function to output a value between 0 and 1 for the \"Home & Living\" and \"Wellness\" category.\n",
    "textcnnmodel.add(layers.Dense(2, activation='sigmoid',kernel_regularizer=regularizers.l2(0.001),bias_regularizer=regularizers.l2(0.001)))\n",
    "\n",
    "# Choice of optimizer: Stochastic Gradient Descent (SGD) seems to take advantage of its learning rate and momentum between each batch to optimize the model’s weights based on the information of the loss function in my case is 'categorical_crossentropy'.\n",
    "# I set learning rate=0.1, as per the source - Source: https://towardsdatascience.com/learning-rate-schedules-and-adaptive-learning-rate-methods-for-deep-learning-2c8f433990d1\n",
    "opt = SGD(lr = 0.1)\n",
    "\n",
    "# We use a binary cross entropy loss function because the problem we are learning is a binary classification problem. \n",
    "textcnnmodel.compile(optimizer = opt,\n",
    "               loss = 'binary_crossentropy',\n",
    "               metrics = ['accuracy','Precision','Recall'])\n",
    "textcnnmodel.summary() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675f312a",
   "metadata": {},
   "source": [
    "## Deep learning: Fitting the text CNN model\n",
    "\n",
    "Parameters:\n",
    "- epochs: first, I tried with 100 epochs but the distance between validation loss and training loss increased so to reduce it I went with 50 epochs.\n",
    "- verbose:1 shows the performance of each epoch\n",
    "- batch_size: 128, was a better batch size for this model\n",
    "- shuffle: False, to get reproducible results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464609a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting on the training model\n",
    "history=textcnnmodel.fit(train_ds.shuffle(2000).batch(128),\n",
    "                     epochs=50,\n",
    "                     verbose=1,\n",
    "                     validation_data=valid_ds.batch(128))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c916f23e",
   "metadata": {},
   "source": [
    "## Deep learning: Evaluations of model\n",
    "For evaluation of this CNN model, I will focus on the evaluation parameter **Recall**. From below code, I can say that the training results are showing as a perfect score so better than the validation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e8c792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the training and validation accuracies\n",
    "loss, accuracy, precision, recall = textcnnmodel.evaluate(Xcnn_train, train_labels, verbose=False)\n",
    "print(\"Training ==> Accuracy: {:.4f}, Precision: {:.4f}, Recall: {:.4f}\".format(accuracy,precision,recall))\n",
    "loss, accuracy, precision, recall = textcnnmodel.evaluate(Xcnn_valid, valid_labels, verbose=False)\n",
    "print(\"Validation ==> Accuracy:  {:.4f}, Precision: {:.4f}, Recall: {:.4f}\".format(accuracy,precision,recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03054e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c38db04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341a1820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "# plt.ylim((-0.1, 1.1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54cd780",
   "metadata": {},
   "source": [
    "### Observations:\n",
    "\n",
    "- Based on the **model.evaluate** I can say that the model is performing well on classifying the data correctly. Talking about **recall**, both shows similar and good outcomes on both training and validation data.\n",
    "- The accuracies for the both the training and validation data was constant for first 20 epochs and then increased at the same pace (parallel to each other) for the next 30 epochs, reaching to 95% and 93% respectively.\n",
    "- Also, the model shows an improved performance on loss too. The loss for both the train and validation data keeps decreasing till the 50 epochs simultaneously and stabilizes at the end."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f56f138",
   "metadata": {},
   "source": [
    "## Deep Learning: Predictions on train, validation and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2ee232",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"******** Training Data ********\")\n",
    "# Make a set of predictions for the training data\n",
    "y_pred = textcnnmodel.predict(Xcnn_train)\n",
    "# y_pred has a predict value for each instance in Xcnn_train\n",
    "print(y_pred.shape)\n",
    "\n",
    "predict_results=y_pred.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1593799",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"******** Training Data ********\")\n",
    "\n",
    "print(metrics.classification_report(y_train_1, predict_results.tolist()))\n",
    "\n",
    "cm=confusion_matrix(y_train_1, predict_results.tolist())\n",
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cm, annot=True, fmt='g', ax=ax, cmap=\"Blues\"); \n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels(['Home & Living', 'Wellness']); ax.yaxis.set_ticklabels(['Home & Living', 'Wellness']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca718e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"******** Validation Data ********\")\n",
    "# Make a set of predictions for the validation data\n",
    "y_pred = textcnnmodel.predict(Xcnn_valid)\n",
    "# y_pred has a predict value for each instance in Xcnn_valid\n",
    "print(y_pred.shape)\n",
    "\n",
    "predict_results=y_pred.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209e2889",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"******** Validation Data ********\")\n",
    "\n",
    "print(metrics.classification_report(y_valid_1, predict_results.tolist()))\n",
    "\n",
    "cm=confusion_matrix(y_valid_1, predict_results.tolist())\n",
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cm, annot=True, fmt='g', ax=ax, cmap=\"Blues\"); \n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels(['Home & Living', 'Wellness']); ax.yaxis.set_ticklabels(['Home & Living', 'Wellness']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18316c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"******** Test Data ********\")\n",
    "# Make a set of predictions for the test data\n",
    "y_pred = textcnnmodel.predict(Xcnn_test)\n",
    "# y_pred has a predict value for each instance in Xcnn_test\n",
    "print(y_pred.shape)\n",
    "\n",
    "predict_results=y_pred.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3745ebe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"******** Test Data ********\")\n",
    "\n",
    "print(metrics.classification_report(y_test_1, predict_results.tolist()))\n",
    "\n",
    "cm=confusion_matrix(y_test_1, predict_results.tolist())\n",
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cm, annot=True, fmt='g', ax=ax, cmap=\"Blues\"); \n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels(['Home & Living', 'Wellness']); ax.yaxis.set_ticklabels(['Home & Living', 'Wellness']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0703c93",
   "metadata": {},
   "source": [
    "### Observations:\n",
    "\n",
    "- The model performed well on all the train, validation and test data.\n",
    "- In comparison, test data showed better performance than the validation set as misclassified 3 lesser data points than validation data for **Home & Living**. So, **recall** was slightly better is case of test data i.e. 85%.\n",
    "- Recall for **Wellness** didn't showed any difference for both validation and test data. Also, precision was similar. Therefore, here because of improvement in Recall score the perdictions was better on test results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63af4f8",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">Step 8</span>\n",
    "\n",
    "# Data Evaluation: SVC & LR model\n",
    "\n",
    "I have decided to choose **Confusion Matrix** as my evaluation metrics because of the following reasons:\n",
    "\n",
    "1. Confusion matrices are not just useful in model evaluation but also model monitoring and model management.\n",
    "2. General accuracy is often not enough information to allow you to decide on a model’s value.\n",
    "3. Confusion matrices can help with side-by-side comparisons of different classification methods. You can see not only how accurate one model is over the other, but also see more granularly how a model does in sensitivity or specificity, as those might be more important factors than general accuracy itself. \n",
    "4. I will look at two factors mainly, __F1 score__ as it is the most common metrics used on unbalanced classification problems as compared to accuracy. Also, as F1 score is a harmonic mean between precision and recall. It will calculate the weighted average of both precision and recall.\n",
    "5. Another one, I will be focussing on the **Recall** percentage which will be like my **primary metric** for minority category 0 (Home & Living). I will try to **increase Recall** score by making an effort to **decrease the false negatives** i.e. I will try to achieve this by classifying the documents which were not correctly assigned to the **Home & Living** category. I think these will be good benchmarks as both better precision and recall will lead to a better model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb5017e",
   "metadata": {},
   "source": [
    "### SVC: Performance on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441c825d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing X and y to evaluate the results of the SVC model on training data:\n",
    "X_cm = X_train_matrix\n",
    "y_true_labels = y_train\n",
    "model = svc_model\n",
    "\n",
    "# Predicting the y-variable i.e. y_pred based on the fitted model on X_training data\n",
    "# Plotting and visualizing the true lables and predicted labels in the confusion matrix\n",
    "y_pred_train = model.predict(X_cm)\n",
    "print(\"SVC ::\\n\")\n",
    "\n",
    "print(\"Confusion matrix for training data:\\n\")\n",
    "print(metrics.classification_report(y_true_labels, y_pred_train, target_names=['Home & Living', 'Wellness']))\n",
    "\n",
    "cm=confusion_matrix(y_true_labels, y_pred_train)\n",
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cm, annot=True, fmt='g', ax=ax, cmap = \"OrRd\"); \n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels(['Home & Living', 'Wellness']); ax.yaxis.set_ticklabels(['Home & Living', 'Wellness']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a295d659",
   "metadata": {},
   "source": [
    "### SVC: Performance on validation data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3388b716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing X and y to evaluate the results of the SVC model on validation data:\n",
    "\n",
    "X_cm = X_valid_matrix\n",
    "y_true_labels = y_valid\n",
    "\n",
    "# Predicting the y-variable i.e. y_pred based on the fitted model on X_valid data\n",
    "# Plotting and visualizing the true lables and predicted labels in the confusion matrix\n",
    "y_pred_val = model.predict(X_cm)\n",
    "print(\"SVC ::\\n\")\n",
    "\n",
    "print(\"Confusion matrix for validation data:\\n\")\n",
    "print(metrics.classification_report(y_true_labels, y_pred_val, target_names=['Home & Living', 'Wellness']))\n",
    "\n",
    "cm=confusion_matrix(y_true_labels, y_pred_val)\n",
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cm, annot=True, fmt='g', ax=ax, cmap = \"OrRd\"); \n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels(['Home & Living', 'Wellness']); ax.yaxis.set_ticklabels(['Home & Living', 'Wellness']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12f43f0",
   "metadata": {},
   "source": [
    "### Logistic Regression: Performance on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bdd457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing X and y to evaluate the results of the Logistic Regression model on training data:\n",
    "X_cm = X_train_matrix\n",
    "y_true_labels = y_train\n",
    "model_1 = l_reg\n",
    "\n",
    "# Predicting the y-variable i.e. y_pred based on the fitted model on X_training data\n",
    "#Plotting and visualizing the true lables and predicted labels in the confusion matrix\n",
    "y_pred_train_l = model_1.predict(X_cm)\n",
    "print(\"Logistic Regression::\\n\")\n",
    "print(\"Confusion matrix for training data:\\n\")\n",
    "print(metrics.classification_report(y_true_labels, y_pred_train_l, target_names=['Home & Living', 'Wellness']))\n",
    "\n",
    "cm=confusion_matrix(y_true_labels, y_pred_train_l)\n",
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cm, annot=True, fmt='g', ax=ax, cmap = \"OrRd\"); \n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels(['Home & Living', 'Wellness']); ax.yaxis.set_ticklabels(['Home & Living', 'Wellness']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be20949",
   "metadata": {},
   "source": [
    "### Logistic Regression: Performance on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668b2648",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Changing X and y to evaluate the results of the Logistic Regression model on validation data:\n",
    "X_cm = X_valid_matrix\n",
    "y_true_labels = y_valid\n",
    "\n",
    "# Predicting the y-variable i.e. y_pred based on the fitted model on X_validation data\n",
    "#Plotting and visualizing the true lables and predicted labels in the confusion matrix\n",
    "y_pred_val_l = model_1.predict(X_cm)\n",
    "\n",
    "print(\"Logistic Regression::\\n\")\n",
    "print(\"Confusion matrix for validation data:\\n\")\n",
    "print(metrics.classification_report(y_true_labels, y_pred_val_l, target_names=['Home & Living', 'Wellness']))\n",
    "\n",
    "cm=confusion_matrix(y_true_labels, y_pred_val_l)\n",
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cm, annot=True, fmt='g', ax=ax, cmap = \"OrRd\"); \n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels(['Home & Living', 'Wellness']); ax.yaxis.set_ticklabels(['Home & Living', 'Wellness']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9790023c",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">Step 9</span>\n",
    "\n",
    "### Performance Comparison: SVC v/s LR \n",
    "\n",
    "- The **Confusion Matrix** for both the models shows pretty good results on the train and validation data considering it an unbalanced dataset. We can also see that the precision is the major contributing factor behind getting a good f1-score. Precision for both the categories in the models is pretty good. However, **recall** performance differs for both the categories. It performs better for majority class \"Wellness\" as comaperd to minority class \"Home & Living\".\n",
    "- We can also see that \"SVC\" performance is **better** as compared to the \"LR\" on both the training and validation data. The reason being, SVM tries to finds the “best” margin (distance between the line and the support vectors) that separates the classes and this reduces the risk of error on the data, while logistic regression does not, instead it can have different decision boundaries with different weights that are near the optimal point.\n",
    "Source: https://medium.com/axum-labs/logistic-regression-vs-support-vector-machines-svm-c335610a3d16#:~:text=SVM%20tries%20to%20finds%20the,are%20near%20the%20optimal%20point.\n",
    "- Also, as there is not much difference between the training and validation **accuracies** that means that both the models aren't **overfitting**. It can be due to the presence of regularization parameter in both the models. However, as expected training f1 scores and accuracies are greater than that of validation data.\n",
    "Source: https://www.quora.com/How-do-we-know-whether-a-model-is-overfitting\n",
    "- Another thing to notice from the classification report is that the **Recall** score for \"Home & Living\" category is far more less for \"Logistic Regression\" model as compared to the \"SVC\" model. In SVC model, about 28 (Train), 23 (Validation) data points were misclassified as Wellness, however, in LR model the count rose to 255 (Train), 51 (Validation) according to the confusion matrix, which proves the second point.\n",
    "- Cumulative F1-scores for both the models on both the training and validation data is approximately **1**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd97128f",
   "metadata": {},
   "source": [
    "### Error Analysis\n",
    "\n",
    "### SVC\n",
    "\n",
    "#### On training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d18db27",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['category_pred'] = y_pred_train\n",
    "train_analysis = train_data.loc[(train_data['CategoryId']==0) & (train_data['category_pred']==1)]\n",
    "#train_analysis.to_csv(\"err_train_svc.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4d935d",
   "metadata": {},
   "source": [
    "#### On validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75ded55",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data['category_pred'] = y_pred_val\n",
    "val_analysis = valid_data.loc[(valid_data['CategoryId']==0) & (valid_data['category_pred']==1)]\n",
    "#val_analysis.to_csv(\"err_val_svc.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d1424f",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82943e17",
   "metadata": {},
   "source": [
    "#### On training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9734ac15",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['category_pred'] = y_pred_train_l\n",
    "train_analysis = train_data.loc[(train_data['CategoryId']==0) & (train_data['category_pred']==1)]\n",
    "#train_analysis.to_csv(\"err_train_lr.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b226bdc9",
   "metadata": {},
   "source": [
    "#### On validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93797652",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data['category_pred'] = y_pred_val_l\n",
    "val_analysis = valid_data.loc[(valid_data['CategoryId']==0) & (valid_data['category_pred']==1)]\n",
    "#val_analysis.to_csv(\"err_val_lr.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e133d935",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">Step 10</span>\n",
    "\n",
    "### Observations\n",
    "\n",
    "- Almost all the records incorrectly predicted by the SVC model were present in the Logistic Regression error analysis csv file. After studying those records I found that many words mentioned in those sentences like \"incandescent\",\"autumn\",\"shipping\",\"nifty\" etc. were rare and unique. Therefore, I assume that they were mis-classified because of their negligible count and classified to the majority class i.e. \"Wellness\" as weighted more.\n",
    "- Furthermore, records containing popular and common words like \"new\",\"make\",\"day\",\"time\" etc. were bound to be mis-classified as \"Wellness\" category because these have much higher count as compared in the \"Home&Living\" category as it has less records. Therefore, again due to imbalance of data records got misclassified. Refer to Step 3(i) or most common words after pre-processing.\n",
    "- We can say that both the models have potential to perform better if we reduce the imbalance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca64a7e",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">Step 11</span>\n",
    "\n",
    "\n",
    "### First Improvement: In Feature Engineering\n",
    "\n",
    "I will set **max_df** parameter in TF-IDF vectorizer to 0.8 so that it doesn't consider most popular common words like \"new\", \"make\", \"day\" for both the categories. It will build a vocabulary  that ignore terms that have a document frequency strictly higher than the given threshold i.e. 0.8\n",
    "\n",
    "Furthermore, I will set **min_df** as 2, which means \"ignore terms that appear in less than 2 document\" to remove rare frequency words.\n",
    "\n",
    "**Sublinear tf-scaling** is set to True, to scale down the weight of term algorithm as it is occurring multiple times(maximum tf) in first document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2526d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_1 = TfidfVectorizer(max_df=0.8, min_df=2, sublinear_tf=True)\n",
    "\n",
    "# Vectorizing training and validation dataset\n",
    "#Fit the vecotrizer on training dataset\n",
    "vectorizer_1.fit(train_data['description'])\n",
    "\n",
    "#Transforming training and validation dataset\n",
    "X_train_matrix_1 = vectorizer_1.transform(train_data['description'])\n",
    "X_valid_matrix_1 = vectorizer_1.transform(valid_data['description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0a0746",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec555c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model_1 = SVC(kernel=\"linear\", C=1.0, random_state=0)\n",
    "svc_model_1.fit(X_train_matrix_1, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253733ab",
   "metadata": {},
   "source": [
    "#### SVC: Training data performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b519d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing X and y to evaluate the results of the SVC model on training data:\n",
    "X_cm = X_train_matrix_1\n",
    "y_true_labels = y_train\n",
    "model = svc_model_1\n",
    "\n",
    "# Predicting the y-variable i.e. y_pred based on the fitted model on X_training data\n",
    "# Plotting and visualizing the true lables and predicted labels in the confusion matrix\n",
    "y_pred_train = model.predict(X_cm)\n",
    "print(\"SVC ::\\n\")\n",
    "\n",
    "print(\"Confusion matrix for training data:\\n\")\n",
    "print(metrics.classification_report(y_true_labels, y_pred_train, target_names=['Home & Living', 'Wellness']))\n",
    "\n",
    "cm=confusion_matrix(y_true_labels, y_pred_train)\n",
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cm, annot=True, fmt='g', ax=ax, cmap='Spectral'); \n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels(['Home & Living', 'Wellness']); ax.yaxis.set_ticklabels(['Home & Living', 'Wellness']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c373b0",
   "metadata": {},
   "source": [
    "#### SVC: Validation data performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ae0d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing X and y to evaluate the results of the SVC model on validation data:\n",
    "\n",
    "X_cm = X_valid_matrix_1\n",
    "y_true_labels = y_valid\n",
    "# Predicting the y-variable i.e. y_pred based on the fitted model on X_valid data\n",
    "# Plotting and visualizing the true lables and predicted labels in the confusion matrix\n",
    "y_pred_val = model.predict(X_cm)\n",
    "print(\"SVC ::\\n\")\n",
    "\n",
    "print(\"Confusion matrix for validation data:\\n\")\n",
    "print(metrics.classification_report(y_true_labels, y_pred_val, target_names=['Home & Living', 'Wellness']))\n",
    "\n",
    "cm=confusion_matrix(y_true_labels, y_pred_val)\n",
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cm, annot=True, fmt='g', ax=ax, cmap='Spectral'); \n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels(['Home & Living', 'Wellness']); ax.yaxis.set_ticklabels(['Home & Living', 'Wellness']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebc5b84",
   "metadata": {},
   "source": [
    "### Logistics Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f23efad",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_reg_1 = LogisticRegression(solver='liblinear', random_state=0)\n",
    "l_reg_1.fit(X_train_matrix_1,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2dc4d35",
   "metadata": {},
   "source": [
    "#### Logistic Regression: Training data performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb73ffcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing X and y to evaluate the results of the Logistic Regression model on training data:\n",
    "X_cm = X_train_matrix_1\n",
    "y_true_labels = y_train\n",
    "model_1 = l_reg_1\n",
    "\n",
    "# Predicting the y-variable i.e. y_pred based on the fitted model on X_training data\n",
    "#Plotting and visualizing the true lables and predicted labels in the confusion matrix\n",
    "y_pred_train_l = model_1.predict(X_cm)\n",
    "print(\"Logistic Regression::\\n\")\n",
    "print(\"Confusion matrix for training data:\\n\")\n",
    "print(metrics.classification_report(y_true_labels, y_pred_train_l, target_names=['Home & Living', 'Wellness']))\n",
    "\n",
    "cm=confusion_matrix(y_true_labels, y_pred_train_l)\n",
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cm, annot=True, fmt='g', ax=ax, cmap='Spectral'); \n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels(['Home & Living', 'Wellness']); ax.yaxis.set_ticklabels(['Home & Living', 'Wellness']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366dca6a",
   "metadata": {},
   "source": [
    "#### Logistic Regression: Validation data performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65088d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing X and y to evaluate the results of the Logistic Regression model on validation data:\n",
    "X_cm = X_valid_matrix_1\n",
    "y_true_labels = y_valid\n",
    "\n",
    "# Predicting the y-variable i.e. y_pred based on the fitted model on X_validation data\n",
    "#Plotting and visualizing the true lables and predicted labels in the confusion matrix\n",
    "y_pred_val_l = model_1.predict(X_cm)\n",
    "\n",
    "print(\"Logistic Regression::\\n\")\n",
    "print(\"Confusion matrix for validation data:\\n\")\n",
    "print(metrics.classification_report(y_true_labels, y_pred_val_l, target_names=['Home & Living', 'Wellness']))\n",
    "\n",
    "cm=confusion_matrix(y_true_labels, y_pred_val_l)\n",
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cm, annot=True, fmt='g', ax=ax, cmap='Spectral'); \n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels(['Home & Living', 'Wellness']); ax.yaxis.set_ticklabels(['Home & Living', 'Wellness']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9b90fc",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "- Changing the parameters in the TF-IDF vectorizer helped to increase the **Recall** percentage of \"Home & Living \" cateogry in the **Logistic Regression** model for both the training and validation datasets. Initially, it was 82% and 83% for train and val respectively however after adding min_df, max_df as parameters it improved to 82% and 83% respectively. Therefore, improving the number of correct predictions by a small margin i.e. decrease in **false negatives** for Home & Living category. \n",
    "\n",
    "- Furthermore, the **Recall** percentage for **SVC**'s training and validation data reduced by 1% respectively for the \"Home & Living\" category respectively. Eariler, it misclassified 23 records and after the parameter change, it increased to 25, while no changes in other predictions related to the Wellness category. Even after a slight difference in recall and precision, model is still providing good f1-score as output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e0c952",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">Step 11</span>\n",
    "\n",
    "### Second Improvement: Changes in the model parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa786581",
   "metadata": {},
   "source": [
    "### SVC\n",
    "\n",
    "#### Parameters\n",
    "- I changed **C** parameter i.e. penality/regularization to **2** to choose a slightly smaller margin so that the model can avoid misclassifying data. I just increased it by 1 because I do not want the model to over-fit. I can further decide a good C value after cross-validation, if SVC comes out to be a better model.\n",
    "\n",
    "Source: https://stackoverflow.com/questions/12809633/parameter-c-in-svm-standard-to-find-best-parameter\n",
    "- I added the **class_weight** parameter to encounter the data imbalance issue. By setting it to **balanced**, it basically means replicating the smaller class until you have as many samples as in the larger one, but in an implicit way.\n",
    "The argument class_weight='balanced' penalizes mistake on the minority class by an amount proportional to how under-represented it is.\n",
    "\n",
    "Source: https://stackoverflow.com/questions/30972029/how-does-the-class-weight-parameter-in-scikit-learn-work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc352bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model_1 = SVC(kernel=\"linear\", C=2.0, random_state=0, class_weight='balanced')\n",
    "svc_model_1.fit(X_train_matrix_1, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b348011",
   "metadata": {},
   "source": [
    "#### Performance on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9789fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing X and y to evaluate the results of the SVC model on training data:\n",
    "X_cm = X_train_matrix_1\n",
    "y_true_labels = y_train\n",
    "model = svc_model_1\n",
    "\n",
    "# Predicting the y-variable i.e. y_pred based on the fitted model on X_training data\n",
    "#Plotting and visualizing the true lables and predicted labels in the confusion matrix\n",
    "y_pred_train = model.predict(X_cm)\n",
    "print(\"SVC ::\\n\")\n",
    "\n",
    "print(\"Confusion matrix for training data:\\n\")\n",
    "print(metrics.classification_report(y_true_labels, y_pred_train, target_names=['Home & Living', 'Wellness']))\n",
    "\n",
    "cm=confusion_matrix(y_true_labels, y_pred_train)\n",
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cm, annot=True, fmt='g', ax=ax); \n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels(['Home & Living', 'Wellness']); ax.yaxis.set_ticklabels(['Home & Living', 'Wellness']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d16857a",
   "metadata": {},
   "source": [
    "#### Performance on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee837ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing X and y to evaluate the results of the SVC model on validation data:\n",
    "\n",
    "X_cm = X_valid_matrix_1\n",
    "y_true_labels = y_valid\n",
    "# Predicting the y-variable i.e. y_pred based on the fitted model on X_valid data\n",
    "#Plotting and visualizing the true lables and predicted labels in the confusion matrix\n",
    "y_pred_val = model.predict(X_cm)\n",
    "print(\"SVC ::\\n\")\n",
    "\n",
    "print(\"Confusion matrix for validation data:\\n\")\n",
    "print(metrics.classification_report(y_true_labels, y_pred_val, target_names=['Home & Living', 'Wellness']))\n",
    "\n",
    "cm=confusion_matrix(y_true_labels, y_pred_val)\n",
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cm, annot=True, fmt='g', ax=ax); \n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels(['Home & Living', 'Wellness']); ax.yaxis.set_ticklabels(['Home & Living', 'Wellness']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1f9f63",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "\n",
    "#### Parameters:\n",
    "- I added the **class_weight** parameter to encounter the data imbalance issue. By setting it to **balanced**, it basically means replicating the smaller class until you have as many samples as in the larger one, but in an implicit way.\n",
    "The argument class_weight='balanced' penalizes mistake on the minority class by an amount proportional to how under-represented it is.\n",
    "\n",
    "Source: https://stackoverflow.com/questions/30972029/how-does-the-class-weight-parameter-in-scikit-learn-work\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4790fa7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_reg_1 = LogisticRegression(solver='liblinear', random_state=0, class_weight='balanced')\n",
    "l_reg_1.fit(X_train_matrix_1,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc4d324",
   "metadata": {},
   "source": [
    "#### Performance on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17fa47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing X and y to evaluate the results of the Logistic Regression model on training data:\n",
    "X_cm = X_train_matrix_1\n",
    "y_true_labels = y_train\n",
    "model_1 = l_reg_1\n",
    "\n",
    "# Predicting the y-variable i.e. y_pred based on the fitted model on X_training data\n",
    "#Plotting and visualizing the true lables and predicted labels in the confusion matrix\n",
    "y_pred_train_l = model_1.predict(X_cm)\n",
    "print(\"Logistic Regression::\\n\")\n",
    "print(\"Confusion matrix for training data:\\n\")\n",
    "print(metrics.classification_report(y_true_labels, y_pred_train_l, target_names=['Home & Living', 'Wellness']))\n",
    "\n",
    "cm=confusion_matrix(y_true_labels, y_pred_train_l)\n",
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cm, annot=True, fmt='g', ax=ax); \n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels(['Home & Living', 'Wellness']); ax.yaxis.set_ticklabels(['Home & Living', 'Wellness']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d535e3",
   "metadata": {},
   "source": [
    "#### Performance on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdb0133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing X and y to evaluate the results of the Logistic Regression model on validation data:\n",
    "X_cm = X_valid_matrix_1\n",
    "y_true_labels = y_valid\n",
    "\n",
    "# Predicting the y-variable i.e. y_pred based on the fitted model on X_validation data\n",
    "#Plotting and visualizing the true lables and predicted labels in the confusion matrix\n",
    "y_pred_val_l = model_1.predict(X_cm)\n",
    "\n",
    "print(\"Logistic Regression::\\n\")\n",
    "print(\"Confusion matrix for validation data:\\n\")\n",
    "print(metrics.classification_report(y_true_labels, y_pred_val_l, target_names=['Home & Living', 'Wellness']))\n",
    "\n",
    "cm=confusion_matrix(y_true_labels, y_pred_val_l)\n",
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cm, annot=True, fmt='g', ax=ax); \n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels(['Home & Living', 'Wellness']); ax.yaxis.set_ticklabels(['Home & Living', 'Wellness']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e4f77e",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "- Adding the **class weight = 'balanced'** parameter improved the performance greatly as shown above, as well as the **recall percentage increased** for both the models in the classification report. Before this, **SVC** was performing better than Logistic regression model but now they both are showing similar f1 scores (differs by 1% for Home & Living) that means that adding class weight has helped the models in better classifications as compared to before as treats the imbalance. The mis-classification in confusion matrix of \"Home and Living\" reduced from 25 to 21.\n",
    "- The **Logistic Regression** model improved more as compared to the SVC model. The **recall** probability score for \"Home and Living\" category rose to 94% from 83% and also without much compromising the precision value i.e. **false negatives** reduced from 48 to 16.\n",
    "- I can say that the benchmark was achieved as I was able to get a better performance of the **Confusion Matrix** by increasing the recall score which indeed increase the f1- score for both the models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37277868",
   "metadata": {},
   "source": [
    "### Saving both the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b29372",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('svc_model.pkl','wb') as f:\n",
    "    pickle.dump(svc_model_1,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b39aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('lr_model.pkl','wb') as f:\n",
    "    pickle.dump(l_reg_1,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6317e1",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">Step 12</span>\n",
    "\n",
    "### Cross Validation on Train+Validation data\n",
    "\n",
    "I am using K-Folds technique as it's popular, easy to understand, it generally results in a less biased model compare to other methods. As it ensures that every observation from the original dataset has the chance of appearing in training and validation set.\n",
    "This is one among the best approach if we have a limited input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996a141a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_data = pd.concat([train_data, valid_data])\n",
    "train_val_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf42ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_data.drop('category_pred', axis=1, inplace=True)\n",
    "train_val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ac6177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am using n_splits as 10 to expect lower prediction error\n",
    "folder = KFold(n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d79745",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_2 = TfidfVectorizer(max_df=0.8, min_df=2, sublinear_tf=True)\n",
    "\n",
    "# Vectorizing training and validation dataset\n",
    "#Fit the vecotrizer on training dataset\n",
    "vectorizer_2.fit(train_val_data['description'])\n",
    "\n",
    "#Transforming training and validation dataset\n",
    "X_train_val_matrix = vectorizer_2.transform(train_val_data['description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4c1dc9",
   "metadata": {},
   "source": [
    "#### SVC: Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342bb560",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(kernel=\"linear\", C=2.0, random_state=0, class_weight='balanced')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b992a4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cross_val_score(svc ,X_train_val_matrix,train_val_data['CategoryId'], cv = folder)# Parameters are, in order - model, X data, labels (y), and the KFold object\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a502fc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame(results, columns=[\"Accuracy_per_fold\"])\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abf16f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "av_val = output[\"Accuracy_per_fold\"].mean()*100\n",
    "print(\"SVC: The average accuracy across folds is {}%\".format(round(av_val,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebe8e88",
   "metadata": {},
   "source": [
    "#### Logistic Regression: Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595986c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_reg_3 = LogisticRegression(solver='liblinear', random_state=0, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143a3e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_lr = cross_val_score(l_reg_3 ,X_train_val_matrix,train_val_data['CategoryId'], cv = folder)# Parameters are, in order - model, X data, labels (y), and the KFold object\n",
    "results_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08512a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame(results_lr, columns=[\"Accuracy_per_fold\"])\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4dbf5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "av_val_1 = output[\"Accuracy_per_fold\"].mean()*100\n",
    "print(\"Logistic Regression: The average accuracy across folds is {}%\".format(round(av_val_1,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90baa1ed",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">Step 13</span>\n",
    "\n",
    "### Observations\n",
    "\n",
    "After performing cross-validation on both the classifers, I got that logistic regression model is performing slightly better the SVC classifier. One of the fold observation of SVC is predicting 93.9% accuracy while none of the accuracies of Logistic Regression came down more than 2 percent of the maximum predicted accuracy.\n",
    "\n",
    "Therefore, I will apply the **Logistic Regression** model on test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cc55d0",
   "metadata": {},
   "source": [
    "### Loading and processing test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b820f9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8deb7317",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.drop('Unnamed: 0',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9342f126",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying same pre-processing steps on test data\n",
    "test_data['description'] = test_data['description'].apply(remove_digits)\n",
    "test_data['description'] = test_data['description'].apply(remove_tags)\n",
    "test_data['description'] = test_data['description'].apply(special_char)\n",
    "test_data['description'] = test_data['description'].apply(convert_lower)\n",
    "test_data['description'] = test_data['description'].apply(remove_stopwords)\n",
    "test_data['description'] = test_data['description'].apply(lemmatize_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec382ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=test_data.loc[:,'description']\n",
    "y_test=test_data.loc[:,'CategoryId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d10a426",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_matrix = vectorizer_1.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea37afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('lr_model.pkl', 'rb') as f:\n",
    "    log_reg = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09683ee5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Changing X and y to evaluate the results of the Logistic Regression model on test data:\n",
    "X_cm = X_test_matrix\n",
    "y_true_labels = y_test\n",
    "model = log_reg\n",
    "\n",
    "# Predicting the y-variable i.e. y_pred based on the fitted model on X_test_matrix data\n",
    "#Plotting and visualizing the true lables and predicted labels in the confusion matrix\n",
    "y_pred_test = model.predict(X_cm)\n",
    "print(\"Logistic Regression ::\\n\")\n",
    "\n",
    "print(\"Confusion matrix for test data:\\n\")\n",
    "print(metrics.classification_report(y_true_labels, y_pred_test, target_names=['Home & Living', 'Wellness']))\n",
    "\n",
    "cm=confusion_matrix(y_true_labels, y_pred_test)\n",
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cm, annot=True, fmt='g', ax=ax); \n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels(['Home & Living', 'Wellness']); ax.yaxis.set_ticklabels(['Home & Living', 'Wellness']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae374ab",
   "metadata": {},
   "source": [
    "### Observations: Validation v/s Test Performance\n",
    "\n",
    "The test data results like precision, f1-scores, accuracy were similar to that of the validation data with some slight variation in the classification i.e. scores on validation data showed slightly better performance than on test data. For instance, if accuracy for validation is predicted 97% then for test it is 96%. And same cases with precision and f1-scores.\n",
    "\n",
    "While if I consider **false negative** (28 data points aren't predicted as Home & Living even though they are) in the confusion matrix then it's quite different. As you can see above that 16 data points of Home & Living category were mis-classified as Wellness for validation data whereas 28 data points were mis-classified as Wellness for test data. Therefore, model showed **better Recall** score on **validation dataset as compared to test dataset**. However, the cumulative accuracies and f1-scores doesn't vary much.\n",
    "\n",
    "I think it's because the model's hyperparameters were tuned specifically for the validation dataset. Overall, I will consider them as good results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefc0dd6",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">Step 14</span>\n",
    "\n",
    "### Re-training LR model on Train+Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b4bee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_reg_final = LogisticRegression(solver='liblinear', random_state=0, class_weight='balanced')\n",
    "l_reg_final.fit(X_train_val_matrix,train_val_data['CategoryId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c755062",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_matrix_2 = vectorizer_2.transform(test_data['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ea1aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing X and y to evaluate the results of the Logistic Regression model on test data:\n",
    "X_cm = X_test_matrix_2\n",
    "y_true_labels = y_test\n",
    "model = l_reg_final\n",
    "\n",
    "# Predicting the y-variable i.e. y_pred based on the fitted model on X_test_matrix_2 data\n",
    "#Plotting and visualizing the true lables and predicted labels in the confusion matrix\n",
    "y_pred_test = model.predict(X_cm)\n",
    "print(\"Logistic Regression ::\\n\")\n",
    "\n",
    "print(\"Confusion matrix for test data:\\n\")\n",
    "print(metrics.classification_report(y_true_labels, y_pred_test, target_names=['Home & Living', 'Wellness']))\n",
    "\n",
    "cm=confusion_matrix(y_true_labels, y_pred_test)\n",
    "plt.figure(figsize=(12,6))\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cm, annot=True, fmt='g', ax=ax, cmap=\"Blues\"); \n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels(['Home & Living', 'Wellness']); ax.yaxis.set_ticklabels(['Home & Living', 'Wellness']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279c391c",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "I didn't find much difference in the classification report metrics for test data evaluations when tested on model fitted with **train data vs train+validation** data. The only changes which I can notice is that **Recall** score for \"Home & Living\" has increased when tested against train+validation data. Earlier it was 91% and now it's 92%.\n",
    "\n",
    "Moreover, in the confusion matrix you can see that after using more data, it is classifying 3 more correct classifications for the minority class (Home&Living) without affecting majority class (Wellness). So, **increased recall** score on Home & Living category."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c91594",
   "metadata": {},
   "source": [
    "### Let's predict category of new articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a456de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Home & Living example: https://www.huffpost.com/entry/how-to-make-home-fancy-hotel_l_62b21aa0e4b06594c1dc6306\n",
    "# Headline+Short Description\n",
    "\n",
    "example=\"How To Make Your Home Feel Like A Fancy Hotel Want to re-create that relaxing vacation environment back home? Follow these expert-backed tips.\"\n",
    "example=example.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07182704",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_vec=vectorizer_2.transform([example])\n",
    "text_arr=my_vec.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cbf0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correctly predicted the category i.e. 0 = Home & Living\n",
    "\n",
    "l_reg_final.predict(text_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6a8c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wellness category example: https://www.huffpost.com/entry/habits-causing-back-pain_l_62c864ece4b0d740198339e8\n",
    "# Headline+Short Description\n",
    "\n",
    "example_2=\"10 Mindless Habits That May Be Causing You Back Pain If your upper, middle or lower back aches, these behaviors might be the culprit.\"\n",
    "example_2=example_2.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a49f7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_vec=vectorizer_2.transform([example_2])\n",
    "text_arr_2=my_vec.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f39e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correctly predicted the category i.e. 1 = Wellness\n",
    "\n",
    "l_reg_final.predict(text_arr_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
